{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9a2a34d",
   "metadata": {},
   "source": [
    "## Ch 8-1 합성곱 신경망의 구성 요소  \n",
    "\n",
    "합성곱은 마치 입력 데이터에 마법의 도장을 찍어서 유용한 특성만 드러나 하는것으로 비유 할수 있다.  \n",
    "앞서 사용한 Dense Network에선 뉴런마다 입력 개수 만큼의 가중치가 있다. 즉 모든 입력에 가중칠를  \n",
    "곱한다. 예를 들어, 밀집층에 뉴런이 3개 있다면 출력은 3개가 된다. 이것은 입력 개수에 상관없다.  \n",
    "이와 달리 합성곱에서는 모두 같은 가중치와 절편을 사용한다. 합성곱 즉, Convolution에서는 뉴련이  \n",
    "입력 위를 이동하면서 출력을 만들기 때문에 뉴런이라고 부르기도 어색하다. 고로 Conv net에서는   \n",
    "뉴런이 아니라 filter라고 부른다. 혹은 kernel이라고 부르기도 함!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccfa284c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\HongongML-DL_stduy\\venv\\Lib\\site-packages\\keras\\src\\export\\tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, \"object\"):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Conv2D name=conv2d, built=False>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.layers.Conv2D(10, kernel_size=(3,3), activation='relu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773a6a56",
   "metadata": {},
   "source": [
    "위 코드에서 Conv2D 클래스의 첫 번째 매개변수는 필터의 개수이다. kernel_size 매개변수는 필터에 사용할  \n",
    "커널의 크기를 지정한다. 필터의 개수와 커널의 크기는 반드시 지정해야 하는 매개변수이다. 마지막으로 밀집  \n",
    "층에서처럼 활성화 함수를 지정한다. 여기서는 렐루 함수를 선택했다. 그럼 특성 맵(feature map)은 activation  \n",
    "function을 적용하기 전이냐? 후이냐?라고 묻는다면 적용한 후 이다. 일반적으로 특성 맵은 활성화 함수를 통과한  \n",
    "값을 나타낸다. 커널의 크기는 하이퍼파라미터니까 당연히 여러 가지 값을 시도해봐야 한다. 하지만 보통은 (3,3)  \n",
    "(5,5) 크기가 많이 사용된다! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418e1e04",
   "metadata": {},
   "source": [
    "#### Padding and Stride  \n",
    "앞서 예로 들었던 합성곱 연산의 예시에서 (4,4) 크기의 입력에 (3,3) 크기의 kernel을 사용하여 (2,2) 크기의  \n",
    "특성 맵을 만들었다. 그런데 만약 kernel의 크기를 그대로 두고 출력의 크기를 입력과 동일하게 하려면 어케해야  \n",
    "할까라는 생각을 할 수 있다! 방법은 바로 Padding이다!  \n",
    "kernel의 크기는 동일한데 출력의 크기가 입력과 동일하려면 입력의 크기가 더 커져야 한다! 이때 입력을 키울때  \n",
    "원본 데이터는 그대로 놔두고 원본 배열의 주위를 가상의 원소로 채우는 것을 Padding이라고 한다. 실제 입력값이  \n",
    "아니기에 Padding은 0으로 채운다. 즉, (4,4) 크기의 입력에 0을 1개 패딩 하면 다음과 같은 (6,6) 크기의 입력  \n",
    "이 된다. 이때 입력과 feature map의 크기를 동일하게 만들기 위해 입력 주위에 0으로 padding하는 것을 same  \n",
    "padding이라고 한다. 이와 반대로 padding 없이 순수한 입력 배열에서만 합성곱을 하여 feature map을 만드는  \n",
    "경우를 valid padding이라고 한다. valid padding은 특성 맵의 크기가 줄어들 수 밖에 없다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2326c96c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Conv2D name=conv2d_1, built=False>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.layers.Conv2D(10, kernel_size=(3,3), activation='relu', padding='same')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b52e6a1",
   "metadata": {},
   "source": [
    "#### Stride  \n",
    "스트라이드는 kernel을 이동하는 크기인데 keras에서는 Conv2D layer에서 매개변수 stride로 정하고  \n",
    "(1,2) 이렇게 아래쪽오 1칸씩 이동하고 오른쪽으로 2칸씩 이동하게 하는 것도 튜플을 사용해서 가능하게 한다.  \n",
    "그러나 실제로 이렇게 kernel의 이동 크기를 가로세로 서로 다르게 하는 경우는 없다!  \n",
    "또 stride의 값을 1보다 크게 사용하는 경우도 거의 드물다고 한다.  \n",
    "고로 대부분 기본값인 1을 사용하면 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42bf3c79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Conv2D name=conv2d_2, built=False>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.layers.Conv2D(10, kernel_size=(3,3), activation='relu', padding='same', strides=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc2ac25",
   "metadata": {},
   "source": [
    "#### Pooling  \n",
    "합성곱 층에서 만든 특성 맵의 가로세로 크기를 줄이는 역할을 수행한다. 하지만 feature map의 개수는 줄이지  \n",
    "않는다. 즉, feature map의 차원을 줄이지는 않는다는 것임! Pooling도 합성곱처럼 입력 위를 지나가면서 도장  \n",
    "을 찍는다. 앞선 convolution과 다른 점은 Pooling의 경우 가중치가 없다는 점이다! 대신에 해당 영역에서 가장  \n",
    "큰 값을 고르거나 평균값을 계산한다. 이를 각각 Max Pooling이나 Average Pooling이라고 한다.  \n",
    "이때 Convolution layer와 Pooling layer를 따로 구분한다. 그리고 Pooling layer에서는 stride의 크기가 해당  \n",
    "Pooling layer의 한 변의 길이와 같다! 즉, Pooling의 크기가 (2,2)면 stride가 2이고 크기가 (3,3)이면 3이 되는  \n",
    "그런 형태라고 할 수 있다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81edef17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MaxPooling2D name=max_pooling2d_1, built=True>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.layers.MaxPooling2D(2)\n",
    "# 대부분 Pooling의 크기는 2이다! 즉, 가로세로를 절반씩 줄이는 것이다!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676f37ee",
   "metadata": {},
   "source": [
    "전체적인 CNN(Convolution Nueral Network) 구조  \n",
    "\n",
    "입력 이미지 데이터 -> Conv layer에서 각 kernel 별로 특징을 추출 -> 각 feature 별 feature map 생성  \n",
    "(보통 H X W X C) -> Pooling layer에서 각 채널별로 Pooling 진행 -> 해당 값을 1차원으로 flatten 후   \n",
    "Dense Network에서 출력함 이때 마지막에 Softmax 함수 사용하면 보통 Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201c1a6a",
   "metadata": {},
   "source": [
    "#### RGB 컬러 이미지에서의 CNN  \n",
    "앞서 본 개념의 예시와 달리 만약 입력 데이터가 3차원의 RGB 컬러까지 가지는 이미지 데이터인 경우에는   \n",
    "입력이 (4,4)가 아니라 (4,4,3)이 된다. 이때 kernel도 2차원이 된다. 즉, filter의 kernel의 크기가   \n",
    "(3,3,3)이 된다. 이때 가중치도 27개가 된다. 중요한 점은 입력이나 filter의 차원이 몇 개인지 상관없이  \n",
    "항상 출력은 하나의 값이라는 점이다. 즉 특성 맵에 있는 한 원소가 채워진다. 참고로 keras의 conv 층은  \n",
    "항상 3차원 입력을 기대하기에 흑백이미지 같은 경우에도 MNIST처럼 (28,28)인 경우 (28,28,1)로 입력해야 한다!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b35888e",
   "metadata": {},
   "source": [
    "Conv1 -> Pooling1 -> Conv2 -> Pooling2 -> ... 처럼 합성곱 층이 깊어질수록 다양한 feature를 추출할 수 있다!  \n",
    "예를 들어, 1번째 conv layer의 filter의 개수가 5개라고 가정하여 첫 번째 Pooling layer를 통과한 feature map  \n",
    "의 크기가 (4,4,5)인 경우 다음 층의 filter의 H와 W가 각각 3이라면 filter의 kernel의 크기는 (3,3,5)가 된다.  \n",
    "왜냐면 입력의 깊이와 필터의 깊이가 기본 CNN에서는 같아야 하기 때문임.  \n",
    "이때 필터 한개가 2 X 2 출력을 만들고 이때 해당 층의 filter가 10개이기 때문에 (2,2,10)이 된다!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
